{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f317c478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T08:40:40.141297Z",
     "start_time": "2023-09-22T08:40:37.785152Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# vector store set up \n",
    "\n",
    "import chromadb\n",
    "\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# LLM\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "# VA with langchain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f61d83",
   "metadata": {},
   "source": [
    "# Chroma Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa0b0ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T08:40:45.429046Z",
     "start_time": "2023-09-22T08:40:40.142291Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\anaconda3\\envs\\LogAnalysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 463 in the collection\n"
     ]
    }
   ],
   "source": [
    "chroma_client = client = chromadb.PersistentClient(path=\"C:/Users/Nathan/Kratos_data-Science/Chroma/v4\")\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Passing a Chroma Client into Langchain\n",
    "\n",
    "langchain_chroma = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=\"Skyminer\",\n",
    "    embedding_function=embedding_function,\n",
    ")\n",
    "print(\"There are\", langchain_chroma._collection.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762aac56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T09:09:43.735211Z",
     "start_time": "2023-09-08T09:09:43.732394Z"
    }
   },
   "source": [
    "# LLM set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6d8e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:27:17.459206Z",
     "start_time": "2023-09-18T08:27:17.454689Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Orca mini\": {\n",
    "        \"Parameters\": \"3b\",\n",
    "        \"model_path\": \"C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\orca-mini-3b.ggmlv3.q4_0.bin\"\n",
    "    },\n",
    "    \"Orca\": {\n",
    "        \"Parameters\": \"13b\",\n",
    "        \"model_path\": \"C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\orca-mini-13b.ggmlv3.q4_0.bin\"\n",
    "    },\n",
    "    \"Falcon\": {\n",
    "        \"Parameters\": \"7b\",\n",
    "        \"model_path\": \"C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\ggml-model-gpt4all-falcon-q4_0.bin\"\n",
    "    },\n",
    "    \"hermes\": {\n",
    "        \"Parameters\": \"13b\",\n",
    "        \"model_path\": \"C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\nous-hermes-13b.ggmlv3.q4_0.bin\"\n",
    "    },\n",
    "    \"Snoozy\": {\n",
    "        \"Parameters\": \"13b\",\n",
    "        \"model_path\": \"C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\GPT4All-13B-snoozy.ggmlv3.q4_0.bin\"\n",
    "    },\n",
    "    \"Wizzard\": {\n",
    "        \"Parameters\": \"13b\",\n",
    "        \"model_path\": \"C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\wizardlm-13b-v1.1-superhot-8k.ggmlv3.q4_0.bin\"\n",
    "    },\n",
    "        \"Llama2\": {\n",
    "        \"Parameters\": \"7b\",\n",
    "        \"model_path\": \"C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\llama-2-7b-chat.ggmlv3.q4_0.bin\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e51e7f",
   "metadata": {},
   "source": [
    "# Chat bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37b3f376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:27:18.415753Z",
     "start_time": "2023-09-18T08:27:18.407288Z"
    }
   },
   "outputs": [],
   "source": [
    "class DocumentationAssistant:\n",
    "    def __init__(self, retriever, llm, num_docs=1, verbose=True):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.num_docs = num_docs\n",
    "        self.verbose = verbose\n",
    "        self.QUESTION_PROMPT_TEMPLATE = \"\"\"\n",
    "        You are an expert on the topic. Based on the provided document excerpts, answer the question: \"{question}\". \n",
    "        Craft a concise and clear response using the provided information. If possible, illustrate with a simple example.\n",
    "        If the information is insufficient, request more details.\n",
    "        ----------\n",
    "        Context: {context}\n",
    "        ----------\n",
    "        \"\"\"\n",
    "\n",
    "    def _print(self, *args, **kwargs):\n",
    "        if self.verbose:\n",
    "            print(*args, **kwargs)\n",
    "\n",
    "    def get_answer(self, query):\n",
    "        # 1. Retrieve relevant documents using the retriever's similarity search\n",
    "        results = self.retriever.similarity_search_with_score(query)\n",
    "\n",
    "        # Print the retrieved documents and their scores\n",
    "        self._print(\"1. Retrieved Documents and their Similarity Scores:\")\n",
    "        for doc, score in results:\n",
    "            self._print(f\"Document: {doc.page_content}... | Score: {score}\")\n",
    "        self._print(\"\\n\")\n",
    "\n",
    "        # 2. Sort the results based on similarity score \n",
    "        # The returned distance score is L2 distance. Therefore, a lower score is better.\n",
    "        sorted_results = sorted(results, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "        # 3. Slice the sorted_results list to get the top num_docs documents\n",
    "        top_docs = sorted_results[:self.num_docs]\n",
    "\n",
    "        # Print the selected documents and their scores\n",
    "        self._print(\"2. Selected Documents for Context:\")\n",
    "        for doc, score in top_docs:\n",
    "            self._print(f\"Document: {doc.page_content}... | Score: {score}\")\n",
    "        self._print(\"\\n\")\n",
    "\n",
    "        # 4. Concatenate the content of the top documents to form the context\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc, score in top_docs])\n",
    "\n",
    "        # 5. Prepare the prompt\n",
    "        prompt = self.QUESTION_PROMPT_TEMPLATE.format(context=context, question=query)\n",
    "\n",
    "        # Print the prepared prompt\n",
    "        self._print(\"3. Prepared Prompt:\")\n",
    "        self._print(prompt)\n",
    "        self._print(\"\\n\")\n",
    "\n",
    "        # 6. Use the prompt with the LLM to get the answer\n",
    "        responses = self.llm.generate([prompt])\n",
    "\n",
    "        # Extract the response from the LLMResult object\n",
    "        response = responses.generations[0][0].text\n",
    "\n",
    "        # Extract and format document sources from the top documents\n",
    "        document_sources = [doc.metadata['source'] for doc, score in top_docs]\n",
    "        sources_string = \"\\n\".join(document_sources)\n",
    "\n",
    "        # Extract the content of the retrieved documents\n",
    "        retrieved_docs = [doc.page_content for doc, score in top_docs]\n",
    "\n",
    "        # Return the final response along with the sources and the retrieved documents\n",
    "        return response, sources_string, retrieved_docs\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58fcdc4",
   "metadata": {},
   "source": [
    "# Generate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d3f496b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:27:19.268852Z",
     "start_time": "2023-09-18T08:27:19.263789Z"
    }
   },
   "outputs": [],
   "source": [
    "def answer_question(question, model_name, num_docs=1, verbose_level=0):\n",
    "    \"\"\"\n",
    "    Answers a given question using the DocumentationAssistant class.\n",
    "    \n",
    "    Parameters:\n",
    "    - question (str): The question to be answered.\n",
    "    - model_name (str): The name of the model to be used from the 'models' dictionary.\n",
    "    - num_docs (int, optional): Number of documents to be retrieved. Defaults to 1.\n",
    "    - verbose_level (int, optional): Level of verbosity.\n",
    "        0: Only prints the answer.\n",
    "        1: Prints the answer and sources.\n",
    "        2: Prints the answer, sources, and verbose outputs from the DocumentationAssistant.\n",
    "        3: Prints the answer, sources, verbose outputs, and retrieved documents.\n",
    "    \n",
    "    Returns:\n",
    "    None. The function prints the results based on the verbosity level.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the model_name is valid\n",
    "    if model_name not in models:\n",
    "        print(f\"Error: Model '{model_name}' not found in the models dictionary.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the retriever, LLM, and DocumentationAssistant\n",
    "    retriever = langchain_chroma  # Assuming you have this retriever instance already\n",
    "    model_details = models[model_name]\n",
    "    model_path = model_details[\"model_path\"]\n",
    "    llm = GPT4All(model=model_path, max_tokens=4000)\n",
    "    assistant = DocumentationAssistant(retriever, llm, num_docs=num_docs)\n",
    "    \n",
    "    # Adjust the verbose attribute based on verbose_level\n",
    "    if verbose_level in [2, 3]:\n",
    "        assistant.verbose = True\n",
    "    else:\n",
    "        assistant.verbose = False\n",
    "\n",
    "    # Get the answer using the DocumentationAssistant\n",
    "    answer, sources, retrieved_docs = assistant.get_answer(question)\n",
    "\n",
    "    # Print the result based on the verbosity level\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Answer:\", answer)\n",
    "    \n",
    "    if verbose_level >= 1:\n",
    "        print(\"Sources:\", sources)\n",
    "    if verbose_level == 3:\n",
    "        print(\"Retrieved Documents:\", retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5b831",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23d264a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:28:31.519067Z",
     "start_time": "2023-09-18T08:27:24.743925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\llama-2-7b-chat.ggmlv3.q4_0.bin\n",
      "Question: How can I use Skyminer for my business \n",
      "Answer: 1. How can I use Skyminer for my business?\n",
      "        You can use Skyminer as a data storage & analytics service for your business in various ways:\n",
      "        a) Monitoring and Analyzing Data : Use Skyminer to store, process ,and analyze large amounts of data from various sources such as logs, metrics, traces, and other data streams . This can help you identify trends, patterns, and anomalies that can inform your business decisions.\n",
      "        b) Building Custom Dashboards: Create custom dashboards using Grafana to visualize and monitor the data stored in Skyminer . This allows you to easily track key performance indicators (KPIs), detect issues ,and make informed decisions based on real-time data.\n",
      "        c) Integration with Other Systems : Use Skyminer as a centralized data storage solution that can be integrated with other systems such as databases, APIs, and third-party tools . This allows you to leverage the power of Skyminer's analytics capabilities across your entire organization.\n",
      "        d) Scalability: Take advantage of Skyminer's scalable architecture to handle large amounts of data from multiple sources without any performance de\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "question = \"How can I use Skyminer for my business \"\n",
    "model_name = \"Llama2\"\n",
    "answer_question(question, model_name, num_docs=1, verbose_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55d1cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:44:56.727396Z",
     "start_time": "2023-09-18T08:43:30.697216Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\llama-2-7b-chat.ggmlv3.q4_0.bin\n",
      "Question: Give me the list of the downsampling aggregators available in skyminer\n",
      "Answer: 1. What are the downsampling aggregators available in Skyminer? Please provide a list of these aggregators along with their uses and parameters.\n",
      "\n",
      "\n",
      "\n",
      "Sources: administration-manual Skyminer Introduction Versions\n",
      "administration-manual Skyminer Introduction Versions\n",
      "user-manual Aggregators Access to Aggregator documentation in Skyminer UI\n",
      "user-manual FAQ What is Skyminer?\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "question = \"Give me the list of the downsampling aggregators available in skyminer\"\n",
    "model_name = \"Llama2\"\n",
    "answer_question(question, model_name, num_docs=4, verbose_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4672f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13934e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dde525bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:54:26.217389Z",
     "start_time": "2023-09-18T08:53:29.013310Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\llama-2-7b-chat.ggmlv3.q4_0.bin\n",
      "Question: tell me about the downsampling aggregators\n",
      "Answer:  Please provide more information on downsampling aggregators, including how they work and what their limitations are.  What does alignment mean in this context? How do you use these parameters to control the behavior of downsampling aggregators? Can you give an example of when each parameter would be useful?\n",
      "Sources: user-manual Aggregators Description/The downsampling aggregators\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "question = \"tell me about the downsampling aggregators\"\n",
    "model_name = \"Llama2\"\n",
    "answer_question(question, model_name, num_docs=1, verbose_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de4cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47096515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d7aa0ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:56:08.327450Z",
     "start_time": "2023-09-18T08:54:26.219153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Question: tell me about the downsampling aggregators\n",
      "Answer:  Downsampling aggregators allow you to reduce the sampling rate of the data points and aggregate these values over a longer period of time. This can be useful when working with large datasets, as it reduces the amount of data that needs to be processed at once.\n",
      "Downsampling aggregators are commonly used in machine learning applications, where they can help improve model accuracy by reducing noise and increasing signal strength. For example, downsampling aggregators can be used to reduce the sampling rate of a time series dataset, so that only the most important data points are retained for analysis. This can result in cleaner and more accurate data, which can then be fed into machine learning models for further analysis.\n",
      "Sources: user-manual Aggregators Description/The downsampling aggregators\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "question = \"tell me about the downsampling aggregators\"\n",
    "model_name = \"Falcon\"\n",
    "answer_question(question, model_name, num_docs=1, verbose_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7144f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad34c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99afc17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4b5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a2ed02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T08:49:48.201231Z",
     "start_time": "2023-09-18T08:49:09.497147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\llama-2-7b-chat.ggmlv3.q4_0.bin\n",
      "1. Retrieved Documents and their Similarity Scores:\n",
      "Document: To access the aggregators documentation , click on the information button in the Skyminer Query interface . Click on the link to “Features documentation” The following window will open , select the tab Aggregator to see details about each aggregator , their use and parameters Error messages Type error : the type returned by the script is not a number { \"errors\" : [ \"Script result should be number , got class java . lang . String\" ] } Syntax error : the JavaScript is not valid { \"errors\" : [ \"query . metric [ 0 ]. aggregators [ 1 ]. m_script has an invalid syntax :[ line & column number ] [ Syntax error message ]\" ] } Allocation limit : the number of points in the range is larger than the maximum size that can be allocated , defined by the skyminer . script_agregator . max_batch property in the configuration file ( only occurs if allocate_array is set to true ) { \"errors\" : [ \"Number of points in aggregation range exceeds configured limit of 1000\" ] }... | Score: 0.4576621949672699\n",
      "Document: Skyminer is a data storage & analytics service . It relies on other server-side high-quality services : Grafana ( dashboard ) and usually Cassandra ( datastore ). Note that third-party software are optional and can be replaced by alternatives to match any need or requirement . cf . Integrated third-party software .... | Score: 0.6654012203216553\n",
      "Document: If the query provides group-by definitions , the query processor generates as many data groups as required . Each data group is then processed as an individual time series . Note If no group-by is defined by the query , Skyminer will merge data from all possible groups into a single time series .... | Score: 0.6699139475822449\n",
      "Document: It takes a Skyminer query in Json format . If correlation mode is Search , the first query will return a single series of data points . Clicking on Create Query button opens a query builder that helps in generating a valid query .... | Score: 0.7019577622413635\n",
      "\n",
      "\n",
      "2. Selected Documents for Context:\n",
      "Document: To access the aggregators documentation , click on the information button in the Skyminer Query interface . Click on the link to “Features documentation” The following window will open , select the tab Aggregator to see details about each aggregator , their use and parameters Error messages Type error : the type returned by the script is not a number { \"errors\" : [ \"Script result should be number , got class java . lang . String\" ] } Syntax error : the JavaScript is not valid { \"errors\" : [ \"query . metric [ 0 ]. aggregators [ 1 ]. m_script has an invalid syntax :[ line & column number ] [ Syntax error message ]\" ] } Allocation limit : the number of points in the range is larger than the maximum size that can be allocated , defined by the skyminer . script_agregator . max_batch property in the configuration file ( only occurs if allocate_array is set to true ) { \"errors\" : [ \"Number of points in aggregation range exceeds configured limit of 1000\" ] }... | Score: 0.4576621949672699\n",
      "\n",
      "\n",
      "3. Prepared Prompt:\n",
      "\n",
      "        You are an expert on the topic. Based on the provided document excerpts, answer the question: \"What is an Aggregator in skyminer ? And how can I use them to generate a query\". \n",
      "        Craft a concise and clear response using the provided information. If possible, illustrate with a simple example.\n",
      "        If the information is insufficient, request more details.\n",
      "        ----------\n",
      "        Context: To access the aggregators documentation , click on the information button in the Skyminer Query interface . Click on the link to “Features documentation” The following window will open , select the tab Aggregator to see details about each aggregator , their use and parameters Error messages Type error : the type returned by the script is not a number { \"errors\" : [ \"Script result should be number , got class java . lang . String\" ] } Syntax error : the JavaScript is not valid { \"errors\" : [ \"query . metric [ 0 ]. aggregators [ 1 ]. m_script has an invalid syntax :[ line & column number ] [ Syntax error message ]\" ] } Allocation limit : the number of points in the range is larger than the maximum size that can be allocated , defined by the skyminer . script_agregator . max_batch property in the configuration file ( only occurs if allocate_array is set to true ) { \"errors\" : [ \"Number of points in aggregation range exceeds configured limit of 1000\" ] }\n",
      "        ----------\n",
      "        \n",
      "\n",
      "\n",
      "Question: What is an Aggregator in skyminer ? And how can I use them to generate a query\n",
      "Answer:  Please provide more information or clarify your question so I can assist you better.\n",
      "Sources: user-manual Aggregators Access to Aggregator documentation in Skyminer UI\n"
     ]
    }
   ],
   "source": [
    "question = \"What is an Aggregator in skyminer ? And how can I use them to generate a query\"\n",
    "model_name = \"Llama2\"\n",
    "answer_question(question, model_name, num_docs=1, verbose_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4f5d5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T09:13:04.584266Z",
     "start_time": "2023-09-18T09:10:32.302947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\Users\\\\Nathan\\\\.cache\\\\gpt4all\\\\ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Question: What is an Aggregator in skyminer ? And how can I use them to generate a query\n",
      "Answer: \n",
      "Aggregators in Skyminer are used to group and aggregate data points from different sources into a single data point. This allows for more efficient querying of the aggregated data. To use aggregators in Skyminer, you can follow these steps:\n",
      "\n",
      "1. Click on the \"Aggregators\" tab in the Skyminer Query interface.\n",
      "2. Select the aggregator you want to use from the list of available aggregators.\n",
      "3. Configure the aggregator by specifying the fields to include in the aggregation and any other relevant parameters.\n",
      "4. Save your aggregator configuration.\n",
      "5. Use your aggregator in your queries by selecting it from the \"Aggregators\" drop-down menu in the query interface.\n",
      "\n",
      "Here's a simple example of how you can use an aggregator to generate a query:\n",
      "\n",
      "Let's say you want to create a query that shows the average temperature for each day of the month. To do this, follow these steps:\n",
      "\n",
      "1. Click on the \"Aggregators\" tab in the Skyminer Query interface.\n",
      "2. Select the \"Sum\" aggregator from the list of available aggregators.\n",
      "3. Configure the aggregator by\n",
      "Sources: user-manual Aggregators Access to Aggregator documentation in Skyminer UI\n",
      "administration-manual Skyminer Architecture Introduction\n"
     ]
    }
   ],
   "source": [
    "question = \"What is an Aggregator in skyminer ? And how can I use them to generate a query\"\n",
    "model_name = \"Falcon\"\n",
    "answer_question(question, model_name, num_docs=2, verbose_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1bc52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
