{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb83fbc0",
   "metadata": {},
   "source": [
    "# Step-by-Step Guide to Building a Chatbot with LangChain\n",
    "\n",
    "This notebook cost around 0.02$ to run using Open Ai api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5f3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983ba31",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c89f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple\n",
    "import logging\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "# Scrapping \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain, ConversationalRetrievalChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import SVMRetriever, MultiQueryRetriever\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0fd57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'your_api_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891c8a9",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1119e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # for web scraping\n",
    "#loader = WebBaseLoader(\"https://docs.your-documentation-link.com/\")\n",
    "#data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4954a9f6",
   "metadata": {},
   "source": [
    "### Get data from docs\n",
    "In this example I chose to work with Langchain [documentation](https://github.com/langchain-ai/langchain/tree/master/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5c1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_mdx_files_content(directory_path):\n",
    "    \"\"\"\n",
    "    Retrieve the content of .mdx files from a specified directory and its subdirectories.\n",
    "    \n",
    "    Args:\n",
    "    - directory_path (str): The path to the directory to search for .mdx files.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A pandas DataFrame containing the filename, filepath, and content of each .mdx file.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"Filename\": [],\n",
    "        \"Filepath\": [],\n",
    "        \"Content\": []\n",
    "    }\n",
    "    \n",
    "    # Walking through the directory\n",
    "    for foldername, subfolders, filenames in os.walk(directory_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".mdx\"):\n",
    "                filepath = os.path.join(foldername, filename)\n",
    "                with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    data[\"Filename\"].append(filename)\n",
    "                    data[\"Filepath\"].append(filepath)\n",
    "                    data[\"Content\"].append(content)\n",
    "    \n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcdddb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve .mdx file contents from the specified directory\n",
    "directory_path = 'C:\\\\Users\\\\Nathan.destrez\\\\Documents\\\\GitHub\\\\virtual-assistant\\\\Chat_bot_proto\\\\docs'  # Replace this with your directory path\n",
    "mdx_dataframe = retrieve_mdx_files_content(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1d5cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>installation.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Installation\\n\\nimport Installation from \"@s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 0\\n---\\n\\n# Introductio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quickstart.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Quickstart\\n\\n## Installation\\n\\nTo install ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>index.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 6\\n---\\n\\nimport DocCar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>index.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 3 \\n---\\n# Comparison E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>analyze_document.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Analyze Document\\n\\nThe AnalyzeDocumentChain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>chat_vector_db.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 2\\n---\\n\\n# Store and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>multi_retrieval_qa_router.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Dynamically select from multiple retrievers\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>question_answering.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># QA over in-memory documents\\n\\nHere we walk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>vector_db_qa.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 1\\n---\\n# QA using a Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Filename  \\\n",
       "0                installation.mdx   \n",
       "1                introduction.mdx   \n",
       "2                  quickstart.mdx   \n",
       "3                       index.mdx   \n",
       "4                       index.mdx   \n",
       "..                            ...   \n",
       "88           analyze_document.mdx   \n",
       "89             chat_vector_db.mdx   \n",
       "90  multi_retrieval_qa_router.mdx   \n",
       "91         question_answering.mdx   \n",
       "92               vector_db_qa.mdx   \n",
       "\n",
       "                                             Filepath  \\\n",
       "0   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "1   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "2   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "3   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "4   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "..                                                ...   \n",
       "88  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "89  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "90  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "91  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "92  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "\n",
       "                                              Content  \n",
       "0   # Installation\\n\\nimport Installation from \"@s...  \n",
       "1   ---\\nsidebar_position: 0\\n---\\n\\n# Introductio...  \n",
       "2   # Quickstart\\n\\n## Installation\\n\\nTo install ...  \n",
       "3   ---\\nsidebar_position: 6\\n---\\n\\nimport DocCar...  \n",
       "4   ---\\nsidebar_position: 3 \\n---\\n# Comparison E...  \n",
       "..                                                ...  \n",
       "88  # Analyze Document\\n\\nThe AnalyzeDocumentChain...  \n",
       "89  ---\\nsidebar_position: 2\\n---\\n\\n# Store and r...  \n",
       "90  # Dynamically select from multiple retrievers\\...  \n",
       "91  # QA over in-memory documents\\n\\nHere we walk ...  \n",
       "92  ---\\nsidebar_position: 1\\n---\\n# QA using a Re...  \n",
       "\n",
       "[93 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdx_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70cae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\nsidebar_position: 0\\n---\\n\\n# Introduction\\n\\n**LangChain** is a framework for developing applications powered by language models. It enables applications that are:\\n- **Data-aware**: connect a language model to other sources of data\\n- **Agentic**: allow a language model to interact with its environment\\n\\nThe main value props of LangChain are:\\n1. **Components**: abstractions for working with language models, along with a collection of implementations for each abstraction. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not\\n2. **Off-the-shelf chains**: a structured assembly of components for accomplishing specific higher-level tasks\\n\\nOff-the-shelf chains make it easy to get started. For more complex applications and nuanced use-cases, components make it easy to customize existing chains or build new ones.\\n\\n## Get started\\n\\n[Hereâ€™s](/docs/get_started/installation.html) how to install LangChain, set up your environment, and start building.\\n\\nWe recommend following our [Quickstart](/docs/get_started/quickstart.html) guide to familiarize yourself with the framework by building your first LangChain application.\\n\\n_**Note**: These docs are for the LangChain [Python package](https://github.com/hwchase17/langchain). For documentation on [LangChain.js](https://github.com/hwchase17/langchainjs), the JS/TS version, [head here](https://js.langchain.com/docs)._\\n\\n## Modules\\n\\nLangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most complex:\\n\\n#### [Model I/O](/docs/modules/model_io/)\\nInterface with language models\\n#### [Data connection](/docs/modules/data_connection/)\\nInterface with application-specific data\\n#### [Chains](/docs/modules/chains/)\\nConstruct sequences of calls\\n#### [Agents](/docs/modules/agents/)\\nLet chains choose which tools to use given high-level directives\\n#### [Memory](/docs/modules/memory/)\\nPersist application state between runs of a chain\\n#### [Callbacks](/docs/modules/callbacks/)\\nLog and stream intermediate steps of any chain\\n\\n## Examples, ecosystem, and resources\\n### [Use cases](/docs/use_cases/)\\nWalkthroughs and best-practices for common end-to-end use cases, like:\\n- [Chatbots](/docs/use_cases/chatbots/)\\n- [Answering questions using sources](/docs/use_cases/question_answering/)\\n- [Analyzing structured data](/docs/use_cases/tabular.html)\\n- and much more...\\n\\n### [Guides](/docs/guides/)\\nLearn best practices for developing with LangChain.\\n\\n### [Ecosystem](/docs/ecosystem/)\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of [integrations](/docs/integrations/) and [dependent repos](/docs/ecosystem/dependents).\\n\\n### [Additional resources](/docs/additional_resources/)\\nOur community is full of prolific developers, creative builders, and fantastic teachers. Check out [YouTube tutorials](/docs/additional_resources/youtube.html) for great tutorials from folks in the community, and [Gallery](https://github.com/kyrolabs/awesome-langchain) for a list of awesome LangChain projects, compiled by the folks at [KyroLabs](https://kyrolabs.com).\\n\\n<h3><span style={{color:\"#2e8555\"}}> Support </span></h3>\\n\\nJoin us on [GitHub](https://github.com/hwchase17/langchain) or [Discord](https://discord.gg/6adMQxSpJS) to ask questions, share feedback, meet other developers building with LangChain, and dream about the future of LLMâ€™s.\\n\\n## API reference\\n\\nHead to the [reference](https://api.python.langchain.com) section for full documentation of all classes and methods in the LangChain Python package.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdx_dataframe.iloc[1]['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63a08f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filename                                              api.mdx\n",
       "Filepath    C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...\n",
       "Content     ---\\nsidebar_position: 0\\n---\\n# API chains\\nA...\n",
       "Name: 87, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdx_dataframe.iloc[87]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6b168",
   "metadata": {},
   "source": [
    "## 3. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec01dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the provided text by:\n",
    "    - Removing HTML tags and content\n",
    "    - Removing Markdown-specific syntax\n",
    "    - Converting Unicode characters to their actual representation\n",
    "    - Removing URLs\n",
    "    - Removing extra white spaces\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input string to be cleaned.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The cleaned string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Remove HTML tags using BeautifulSoup\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    no_html = soup.get_text(separator=' ')\n",
    "    \n",
    "    # 2. Remove Markdown Syntax\n",
    "    # Common markdown syntax: **bold**, *italic*, # Headings, ![alt_text](url), [text](url)\n",
    "    no_markdown = re.sub(r'\\!\\[.*?\\]\\(.*?\\)|\\[(.*?)\\]\\(.*?\\)|\\*\\*.*?\\*\\*|\\*.*?\\*|#[^\\n]*', '', no_html)\n",
    "    \n",
    "    # 3. Convert Unicode characters (for common entities; can be expanded further)\n",
    "    no_unicode = re.sub(r'&amp;', '&', no_markdown)\n",
    "    no_unicode = re.sub(r'&lt;', '<', no_unicode)\n",
    "    no_unicode = re.sub(r'&gt;', '>', no_unicode)\n",
    "    \n",
    "    # 4. Remove URLs\n",
    "    no_urls = re.sub(r'http[s]?://\\S+', '', no_unicode)\n",
    "    \n",
    "    # 5. Remove extra white spaces\n",
    "    clean_string = ' '.join(no_urls.split())\n",
    "    \n",
    "    return clean_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5adb9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to the entire 'Content' column\n",
    "mdx_dataframe['Cleaned_Content'] = mdx_dataframe['Content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81907a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Content</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>installation.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Installation\\n\\nimport Installation from \"@s...</td>\n",
       "      <td>import Installation from \"@snippets/get_starte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 0\\n---\\n\\n# Introductio...</td>\n",
       "      <td>--- sidebar_position: 0 --- is a framework for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quickstart.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Quickstart\\n\\n## Installation\\n\\nTo install ...</td>\n",
       "      <td>To install LangChain run: import Tabs from '@t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>index.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 6\\n---\\n\\nimport DocCar...</td>\n",
       "      <td>--- sidebar_position: 6 --- import DocCardList...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>index.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 3 \\n---\\n# Comparison E...</td>\n",
       "      <td>--- sidebar_position: 3 --- Comparison evaluat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>analyze_document.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Analyze Document\\n\\nThe AnalyzeDocumentChain...</td>\n",
       "      <td>The AnalyzeDocumentChain can be used as an end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>chat_vector_db.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 2\\n---\\n\\n# Store and r...</td>\n",
       "      <td>--- sidebar_position: 2 --- The Conversational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>multi_retrieval_qa_router.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># Dynamically select from multiple retrievers\\...</td>\n",
       "      <td>This notebook demonstrates how to use the `Rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>question_answering.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td># QA over in-memory documents\\n\\nHere we walk ...</td>\n",
       "      <td>Here we walk through how to use LangChain for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>vector_db_qa.mdx</td>\n",
       "      <td>C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...</td>\n",
       "      <td>---\\nsidebar_position: 1\\n---\\n# QA using a Re...</td>\n",
       "      <td>--- sidebar_position: 1 --- This example showc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Filename  \\\n",
       "0                installation.mdx   \n",
       "1                introduction.mdx   \n",
       "2                  quickstart.mdx   \n",
       "3                       index.mdx   \n",
       "4                       index.mdx   \n",
       "..                            ...   \n",
       "88           analyze_document.mdx   \n",
       "89             chat_vector_db.mdx   \n",
       "90  multi_retrieval_qa_router.mdx   \n",
       "91         question_answering.mdx   \n",
       "92               vector_db_qa.mdx   \n",
       "\n",
       "                                             Filepath  \\\n",
       "0   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "1   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "2   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "3   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "4   C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "..                                                ...   \n",
       "88  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "89  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "90  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "91  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "92  C:\\Users\\Nathan.destrez\\Documents\\GitHub\\virtu...   \n",
       "\n",
       "                                              Content  \\\n",
       "0   # Installation\\n\\nimport Installation from \"@s...   \n",
       "1   ---\\nsidebar_position: 0\\n---\\n\\n# Introductio...   \n",
       "2   # Quickstart\\n\\n## Installation\\n\\nTo install ...   \n",
       "3   ---\\nsidebar_position: 6\\n---\\n\\nimport DocCar...   \n",
       "4   ---\\nsidebar_position: 3 \\n---\\n# Comparison E...   \n",
       "..                                                ...   \n",
       "88  # Analyze Document\\n\\nThe AnalyzeDocumentChain...   \n",
       "89  ---\\nsidebar_position: 2\\n---\\n\\n# Store and r...   \n",
       "90  # Dynamically select from multiple retrievers\\...   \n",
       "91  # QA over in-memory documents\\n\\nHere we walk ...   \n",
       "92  ---\\nsidebar_position: 1\\n---\\n# QA using a Re...   \n",
       "\n",
       "                                      Cleaned_Content  \n",
       "0   import Installation from \"@snippets/get_starte...  \n",
       "1   --- sidebar_position: 0 --- is a framework for...  \n",
       "2   To install LangChain run: import Tabs from '@t...  \n",
       "3   --- sidebar_position: 6 --- import DocCardList...  \n",
       "4   --- sidebar_position: 3 --- Comparison evaluat...  \n",
       "..                                                ...  \n",
       "88  The AnalyzeDocumentChain can be used as an end...  \n",
       "89  --- sidebar_position: 2 --- The Conversational...  \n",
       "90  This notebook demonstrates how to use the `Rou...  \n",
       "91  Here we walk through how to use LangChain for ...  \n",
       "92  --- sidebar_position: 1 --- This example showc...  \n",
       "\n",
       "[93 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdx_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84a296ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--- sidebar_position: 0 --- is a framework for developing applications powered by language models. It enables applications that are: - : connect a language model to other sources of data - : allow a language model to interact with its environment The main value props of LangChain are: 1. : abstractions for working with language models, along with a collection of implementations for each abstraction. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not 2. : a structured assembly of components for accomplishing specific higher-level tasks Off-the-shelf chains make it easy to get started. For more complex applications and nuanced use-cases, components make it easy to customize existing chains or build new ones. how to install LangChain, set up your environment, and start building. We recommend following our guide to familiarize yourself with the framework by building your first LangChain application. _: These docs are for the LangChain . For documentation on , the JS/TS version, ._ LangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most complex: Interface with language models Interface with application-specific data Construct sequences of calls Let chains choose which tools to use given high-level directives Persist application state between runs of a chain Log and stream intermediate steps of any chain Walkthroughs and best-practices for common end-to-end use cases, like: - - - - and much more... Learn best practices for developing with LangChain. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of and . Our community is full of prolific developers, creative builders, and fantastic teachers. Check out for great tutorials from folks in the community, and for a list of awesome LangChain projects, compiled by the folks at . Support Join us on or to ask questions, share feedback, meet other developers building with LangChain, and dream about the future of LLMâ€™s. Head to the section for full documentation of all classes and methods in the LangChain Python package.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdx_dataframe.iloc[1][\"Cleaned_Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff176e28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To install LangChain run: import Tabs from \\'@theme/Tabs\\'; import TabItem from \\'@theme/TabItem\\'; import Install from \"@snippets/get_started/quickstart/installation.mdx\" For more details, see our . Using LangChain will usually require integrations with one or more model providers, data stores, APIs, etc. For this example, we\\'ll use OpenAI\\'s model APIs. import OpenAISetup from \"@snippets/get_started/quickstart/openai_setup.mdx\" Now we can start building our language model application. LangChain provides many modules that can be used to build language model applications. Modules can be used as stand-alones in simple applications and they can be combined for more complex use cases. The core building block of LangChain applications is the LLMChain. This combines three things: - LLM: The language model is the core reasoning engine here. In order to work with LangChain, you need to understand the different types of language models and how to work with them. - Prompt Templates: This provides instructions to the language model. This controls what the language model outputs, so understanding how to construct prompts and different prompting strategies is crucial. - Output Parsers: These translate the raw response from the LLM to a more workable format, making it easy to use the output downstream. In this getting started guide we will cover those three components by themselves, and then cover the LLMChain which combines all of them. Understanding these concepts will set you up well for being able to use and customize LangChain applications. Most LangChain applications allow you to configure the LLM and/or the prompt used, so knowing how to take advantage of this will be a big enabler. There are two types of language models, which in LangChain are called: - LLMs: this is a language model which takes a string as input and returns a string - ChatModels: this is a language model which takes a list of messages as input and returns a message The input/output for LLMs is simple and easy to understand - a string. But what about ChatModels? The input there is a list of `ChatMessage`s, and the output is a single `ChatMessage`. A `ChatMessage` has two required components: - `content`: This is the content of the message. - `role`: This is the role of the entity from which the `ChatMessage` is coming from. LangChain provides several objects to easily distinguish between different roles: - `HumanMessage`: A `ChatMessage` coming from a human/user. - `AIMessage`: A `ChatMessage` coming from an AI/assistant. - `SystemMessage`: A `ChatMessage` coming from the system. - `FunctionMessage`: A `ChatMessage` coming from a function call. If none of those roles sound right, there is also a `ChatMessage` class where you can specify the role manually. For more information on how to use these different messages most effectively, see our prompting guide. LangChain exposes a standard interface for both, but it\\'s useful to understand this difference in order to construct prompts for a given language model. The standard interface that LangChain exposes has two methods: - `predict`: Takes in a string, returns a string - `predict_messages`: Takes in a list of messages, returns a message. Let\\'s see how to work with these different types of models and these different types of inputs. First, let\\'s import an LLM and a ChatModel. import ImportLLMs from \"@snippets/get_started/quickstart/import_llms.mdx\" The `OpenAI` and `ChatOpenAI` objects are basically just configuration objects. You can initialize them with parameters like `temperature` and others, and pass them around. Next, let\\'s use the `predict` method to run over a string input. import InputString from \"@snippets/get_started/quickstart/input_string.mdx\" Finally, let\\'s use the `predict_messages` method to run over a list of messages. import InputMessages from \"@snippets/get_started/quickstart/input_messages.mdx\" For both these methods, you can also pass in parameters as key word arguments. For example, you could pass in `temperature=0` to adjust the temperature that is used from what the object was configured with. Whatever values are passed in during run time will always override what the object was configured with. Most LLM applications do not pass user input directly into an LLM. Usually they will add the user input to a larger piece of text, called a prompt template, that provides additional context on the specific task at hand. In the previous example, the text we passed to the model contained instructions to generate a company name. For our application, it\\'d be great if the user only had to provide the description of a company/product, without having to worry about giving the model instructions. PromptTemplates help with exactly this! They bundle up all the logic for going from user input into a fully formatted prompt. This can start off very simple - for example, a prompt to produce the above string would just be: import PromptTemplateLLM from \"@snippets/get_started/quickstart/prompt_templates_llms.mdx\" import PromptTemplateChatModel from \"@snippets/get_started/quickstart/prompt_templates_chat_models.mdx\" However, the advantages of using these over raw string formatting are several. You can \"partial\" out variables - eg you can format only some of the variables at a time. You can compose them together, easily combining different templates into a single prompt. For explanations of these functionalities, see the for more detail. PromptTemplates can also be used to produce a list of messages. In this case, the prompt not only contains information about the content, but also each message (its role, its position in the list, etc) Here, what happens most often is a ChatPromptTemplate is a list of ChatMessageTemplates. Each ChatMessageTemplate contains instructions for how to format that ChatMessage - its role, and then also its content. Let\\'s take a look at this below: ChatPromptTemplates can also include other things besides ChatMessageTemplates - see the for more detail. OutputParsers convert the raw output of an LLM into a format that can be used downstream. There are few main type of OutputParsers, including: - Convert text from LLM -> structured information (eg JSON) - Convert a ChatMessage into just a string - Convert the extra information returned from a call besides the message (like OpenAI function invocation) into a string. For full information on this, see the In this getting started guide, we will write our own output parser - one that converts a comma separated list into a list. import OutputParser from \"@snippets/get_started/quickstart/output_parser.mdx\" We can now combine all these into one chain. This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to an LLM, and then pass the output through an (optional) output parser. This is a convenient way to bundle up a modular piece of logic. Let\\'s see it in action! import LLMChain from \"@snippets/get_started/quickstart/llm_chain.mdx\" This is it! We\\'ve now gone over how to create the core building block of LangChain applications - the LLMChains. There is a lot more nuance in all these components (LLMs, prompts, output parsers) and a lot more different components to learn about as well. To continue on your journey: - into LLMs, prompts, and output parsers - Learn the other - Check out our for detailed walkthroughs on particular topics - Explore'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdx_dataframe.iloc[2][\"Cleaned_Content\"] #see if the code is still there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6260147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleane Filename columns\n",
    "def remove_mdx_extension(df):\n",
    "    df['Filename'] = df['Filename'].str.replace('.mdx', '', regex=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "563b45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdx_dataframe = remove_mdx_extension(mdx_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443b978",
   "metadata": {},
   "source": [
    "### Turn into list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf96b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_txt = [f\"{row['Filename']} {row['Cleaned_Content']}\" for index, row in mdx_dataframe.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c5988e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_txt) # should be equal to number of row of Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aafd3440",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'introduction --- sidebar_position: 0 --- is a framework for developing applications powered by language models. It enables applications that are: - : connect a language model to other sources of data - : allow a language model to interact with its environment The main value props of LangChain are: 1. : abstractions for working with language models, along with a collection of implementations for each abstraction. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not 2. : a structured assembly of components for accomplishing specific higher-level tasks Off-the-shelf chains make it easy to get started. For more complex applications and nuanced use-cases, components make it easy to customize existing chains or build new ones. how to install LangChain, set up your environment, and start building. We recommend following our guide to familiarize yourself with the framework by building your first LangChain application. _: These docs are for the LangChain . For documentation on , the JS/TS version, ._ LangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most complex: Interface with language models Interface with application-specific data Construct sequences of calls Let chains choose which tools to use given high-level directives Persist application state between runs of a chain Log and stream intermediate steps of any chain Walkthroughs and best-practices for common end-to-end use cases, like: - - - - and much more... Learn best practices for developing with LangChain. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of and . Our community is full of prolific developers, creative builders, and fantastic teachers. Check out for great tutorials from folks in the community, and for a list of awesome LangChain projects, compiled by the folks at . Support Join us on or to ask questions, share feedback, meet other developers building with LangChain, and dream about the future of LLMâ€™s. Head to the section for full documentation of all classes and methods in the LangChain Python package.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_txt[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153a4a1",
   "metadata": {},
   "source": [
    "### Format text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b124c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "Document = namedtuple(\"Document\", [\"page_content\", \"metadata\", \"ids\"])\n",
    "\n",
    "all_dtxt = [\n",
    "    Document(\n",
    "        page_content=txt, \n",
    "        metadata={'title': txt.split(' ')[0]},  # Wrap the first word in a dictionary\n",
    "        ids=f\"v{i+1}\"\n",
    "    ) \n",
    "    for i, txt in enumerate(all_txt)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22576997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='installation import Installation from \"@snippets/get_started/installation.mdx\"', metadata={'title': 'installation'}, ids='v1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dtxt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888f4cc",
   "metadata": {},
   "source": [
    "## 4. Data Storing & Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb98ff89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_dtxt, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60a8b921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['4ef7fe1e-35f2-11ee-ad0c-c43d1a21bde3'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'title': 'installation'}],\n",
       " 'documents': ['installation import Installation from \"@snippets/get_started/installation.mdx\"']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first 10 vectors\n",
    "vectors = vectorstore.get(limit=1)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cced05",
   "metadata": {},
   "source": [
    "## 5. Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60a6b5",
   "metadata": {},
   "source": [
    "Define custom retriever or use the vectorstore one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bab890f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_retriever = SVMRetriever.from_documents(all_dtxt, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5291e3",
   "metadata": {},
   "source": [
    "## 6. Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4f76d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(),chain_type=\"stuff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb5649",
   "metadata": {},
   "source": [
    "## 7. Customizations (Optional)\n",
    "- Prompt Customization: Customize the prompt for your chatbot if needed.\n",
    "- Return Source Documents: If you want to return the full set of retrieved documents for answer generation, set return_source_documents=True in the RetrievalQA chain.\n",
    "- Return Citations: For answer citations, use RetrievalQAWithSourcesChain.\n",
    "- Customizing Retrieved Document Processing: Choose different methods to pass retrieved documents to the LLM (like stuff)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f608e",
   "metadata": {},
   "source": [
    "## 8. Implementing Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "308d15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "retriever = vectorstore.as_retriever()\n",
    "chat = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d9c7e",
   "metadata": {},
   "source": [
    "## 9. Use the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edbc2439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework for developing applications powered by language models. It provides standard, extendable interfaces and external integrations for interfacing with language models and application-specific data. LangChain allows you to construct sequences of calls and choose which tools to use based on high-level directives. It also enables you to persist application state between runs of a chain and log and stream intermediate steps of any chain. LangChain offers off-the-shelf chains for easy application development and customization options for more complex use cases. It is part of a rich ecosystem of tools and has a supportive community.\n"
     ]
    }
   ],
   "source": [
    "result = chat({\"question\": \"What is langchain\"})\n",
    "print(result['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d991bda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, custom IDs can be defined in Chroma DB. Chroma DB allows you to assign custom IDs to documents or data points in your database. These custom IDs can be used to uniquely identify and retrieve specific documents or data points when querying the database.\n"
     ]
    }
   ],
   "source": [
    "result = chat({\"question\": \"Can I define custom ids in chroma DB\"})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d9ec5d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some interesting facts about the LangChain framework that might help you develop your own chatbot on custom data:\n",
      "\n",
      "1. Memory System: LangChain provides utilities for adding memory to a conversational system. The memory system supports reading and writing actions, allowing the chatbot to refer to past interactions and store information for future runs.\n",
      "\n",
      "2. Data Structures and Algorithms: LangChain offers various data structures and algorithms for working with memory types. These structures and algorithms help in organizing and querying chat messages, allowing you to retrieve relevant information efficiently.\n",
      "\n",
      "3. Integration with Model Providers: LangChain allows you to integrate with different model providers, such as OpenAI's model APIs. This integration enables you to leverage pre-trained language models for your chatbot.\n",
      "\n",
      "4. LLMs and Chat Models: LangChain supports two types of models - LLMs (Language Model) and Chat Models. LLMs are text completion models that take a string as input and return a string as output. Chat Models are specifically designed for conversations and take a list of chat messages as input, returning a chat message as output.\n",
      "\n",
      "5. Prompt Templates: LangChain provides Prompt Templates, which help in constructing prompts for language models. Prompt Templates allow you to bundle instructions and context with user input, making it easier to generate meaningful responses.\n",
      "\n",
      "6. Output Parsers: LangChain offers Output Parsers that convert the raw output of a language model into a more workable format. These parsers help in extracting structured information from the model's response, making it easier to process and use the output.\n",
      "\n",
      "7. Modular Architecture: LangChain follows a modular architecture, allowing you to combine different components like LLMs, prompt templates, and output parsers to create a customized chatbot. This modular approach provides flexibility and extensibility in developing your chatbot.\n",
      "\n",
      "8. Documentation and Resources: LangChain provides detailed documentation and resources to help you understand and utilize its features effectively. The documentation covers various topics like getting started, advanced topics, custom memory systems, and more.\n",
      "\n",
      "By leveraging these features and resources, you can develop a chatbot on custom data using the LangChain framework.\n"
     ]
    }
   ],
   "source": [
    "result = chat({\"question\": \"Tell me interesting facts about Langchain framework that might help me developping my own chatbot on custom data\"})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1b43bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One cool use case where the LangChain framework is useful is in question answering over a list of documents. With LangChain, you can connect a language model to other sources of data and allow it to interact with its environment. This means you can build applications that can answer questions by analyzing a collection of documents.\n",
      "\n",
      "For example, let's say you have a large database of scientific research papers. You can use LangChain to create a question answering system that takes a user's question as input and searches through the research papers to find the most relevant information. The system can then provide the user with a concise and accurate answer to their question.\n",
      "\n",
      "This use case can be particularly useful in fields like academia, where researchers often need to sift through a large amount of information to find answers to their questions. LangChain simplifies the process by automating the search and analysis of documents, making it faster and more efficient for researchers to find the information they need.\n",
      "\n",
      "By leveraging the power of language models and the flexibility of the LangChain framework, you can create intelligent question answering systems that can handle complex queries and provide accurate answers from a diverse range of documents.\n"
     ]
    }
   ],
   "source": [
    "result = chat({\"question\": \"Give me example of cool use case where langchain is useful\"})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e91cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
