{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1af13c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39f936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:22.423512Z",
     "start_time": "2023-09-19T16:24:16.731401Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import html\n",
    "import re\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Chroma\n",
    "import chromadb \n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Sentence Transformers\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fad0eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:22.427709Z",
     "start_time": "2023-09-19T16:24:22.424507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8e07e",
   "metadata": {},
   "source": [
    "# Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81c6cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:22.432443Z",
     "start_time": "2023-09-19T16:24:22.428706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'site1': {\n",
    "        'index_path': \"http://192.168.48.101/jupyter/view/VA_project/extracted_content_A_manual/administration-manual-html/index.html\",\n",
    "        'base_path': \"http://192.168.48.101/jupyter/tree/VA_project/extracted_content_A_manual/administration-manual-html\",\n",
    "        'documentation': 'administration-manual'\n",
    "    },\n",
    "    'site2': {\n",
    "        'index_path': \"http://192.168.48.101/jupyter/view/VA_project/extracted_content_U_manual/user-manual-html/index.html\",\n",
    "        'base_path': \"http://192.168.48.101/jupyter/tree/VA_project/extracted_content_U_manual/user-manual-html\",\n",
    "        'documentation': 'user-manual'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10419e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:22.437920Z",
     "start_time": "2023-09-19T16:24:22.434438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to read the local HTML file\n",
    "def read_local_html(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.warning(f\"File not found: {file_path}\")\n",
    "        return ''\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7e108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:22.442704Z",
     "start_time": "2023-09-19T16:24:22.438922Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_path(html_content, h='h1'):\n",
    "    html_content.split(f'</{h}>', 0)\n",
    "    soup = BeautifulSoup(html_content.split(f'</{h}>')[0], 'html.parser')\n",
    "    h_text = soup.find(f'{h}').text.replace(\"¶\", \"\")\n",
    "    return '/' + h_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce2575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:22.451402Z",
     "start_time": "2023-09-19T16:24:22.443706Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_content_from_page(html_content, source, file_path):\n",
    "    h1_split = html_content.split('<h1')\n",
    "    list_split = list()\n",
    "    list_path = list()\n",
    "    list_source = list()  # For storing the documentation source\n",
    "    path = ''\n",
    "\n",
    "    for i, h1 in enumerate(h1_split):\n",
    "        if i > 0:\n",
    "            h1 = '<h1' + h1\n",
    "            result = path.split('/')[:1] \n",
    "            path = '/'.join(result)\n",
    "            path += get_path(h1, h='h1')      \n",
    "\n",
    "        h2_split = h1.split('<h2')\n",
    "        for j, h2 in enumerate(h2_split):\n",
    "            if j > 0:\n",
    "                h2 = '<h2' + h2\n",
    "                result = path.split('/')[:2] \n",
    "                path = '/'.join(result)\n",
    "                path += get_path(h2, h='h2')\n",
    "                \n",
    "            h3_split = h2.split('<h3')\n",
    "            for k, h3 in enumerate(h3_split):\n",
    "                if k > 0:\n",
    "                    h3 = '<h3' + h3\n",
    "                    result = path.split('/')[:3] \n",
    "                    path = '/'.join(result)\n",
    "                    path += get_path(h3, h='h3')\n",
    "\n",
    "                h4_split = h3.split('<h4')\n",
    "                for l, h4 in enumerate(h4_split):\n",
    "                    if l > 0: \n",
    "                        h4 = '<h4' + h4\n",
    "                        result = path.split('/')[:4] \n",
    "                        path = '/'.join(result)\n",
    "                        path += get_path(h4, h='h4')    \n",
    "\n",
    "                    h5_split = h4.split('<h5') \n",
    "                    soup = BeautifulSoup(h5_split[0].split('\\n', 1)[1], \"lxml\")\n",
    "                    h5_split = soup.get_text().strip('\\n')\n",
    "                    list_split.append(h5_split) \n",
    "                    list_path.append(path)\n",
    "                    list_source.append(source)  # Add the documentation source for each content\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['documentation'] = list_source  # Add the documentation source column\n",
    "    df['path'] = list_path\n",
    "    df['text'] = list_split\n",
    "    df['file_path'] = file_path  # adding local path to the df for each row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedd04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:22.457394Z",
     "start_time": "2023-09-19T16:24:22.452397Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_links(site_config):\n",
    "    index_content = read_local_html(site_config['index_path'])\n",
    "    soup = BeautifulSoup(index_content, 'html.parser')\n",
    "    links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].endswith('.html')]\n",
    "    \n",
    "    logging.info(f\"Found {len(links)} links to process for {site_config['documentation']}.\")\n",
    "    \n",
    "    data_frames = []\n",
    "    for link in links:\n",
    "        full_path = os.path.join(site_config['base_path'], link)  # Using os.path.join\n",
    "        try:\n",
    "            page_content = read_local_html(full_path)\n",
    "            df_temp = scrape_content_from_page(page_content, site_config['documentation'], full_path)\n",
    "            \n",
    "            # Check if df_temp is not empty or None\n",
    "            if df_temp is not None and not df_temp.empty:\n",
    "                data_frames.append(df_temp)\n",
    "            else:\n",
    "                logging.warning(f\"Empty dataframe returned from {full_path}.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {full_path}: {e}\")\n",
    "    \n",
    "    logging.info(f\"Processed {len(data_frames)} dataframes for {site_config['documentation']}.\")\n",
    "    return data_frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ed82e",
   "metadata": {},
   "source": [
    "# Scrape the Content and Store in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, site_config in config.items():\n",
    "    result = process_links(site_config)\n",
    "    print(f\"For {key}, process_links returns:\", result)\n",
    "    all_data_frames.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b26b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.892203Z",
     "start_time": "2023-09-19T16:24:22.458389Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_frames = []\n",
    "for key, site_config in config.items():\n",
    "    all_data_frames.extend(process_links(site_config))\n",
    "\n",
    "df = pd.concat(all_data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfe99f",
   "metadata": {},
   "source": [
    "# Turn to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727b9ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.905270Z",
     "start_time": "2023-09-19T16:24:23.893198Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2ec68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.911365Z",
     "start_time": "2023-09-19T16:24:23.907272Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3a0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.916126Z",
     "start_time": "2023-09-19T16:24:23.912367Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[89,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05ba82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.921346Z",
     "start_time": "2023-09-19T16:24:23.917129Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[336,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440daa1f",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad986ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.927096Z",
     "start_time": "2023-09-19T16:24:23.922342Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Whitespace normalization\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Handling newline characters to create a visual separation\n",
    "    text = text.replace('\\n', ' NEWLINE ')\n",
    "\n",
    "    # Handle LaTeX math expressions: This step can be enhanced further based on specific needs\n",
    "    # The idea here is to isolate math expressions so that they don't get affected by other cleaning operations\n",
    "    math_expressions = re.findall(r'\\\\\\(.*?\\\\\\)', text)\n",
    "    for math_expr in math_expressions:\n",
    "        placeholder = math_expr.replace(' ', '_')\n",
    "        text = text.replace(math_expr, placeholder)\n",
    "\n",
    "    # Removing unwanted characters like ¶\n",
    "    text = text.replace('¶', '')\n",
    "\n",
    "    # Punctuation spacing: Ensure spaces before and after punctuation\n",
    "    text = re.sub(r'(?<=[\\w])([.,;:!?\\(\\)\\[\\]])', r' \\1', text)\n",
    "    text = re.sub(r'([.,;:!?\\(\\)\\[\\]])(?=[\\w])', r'\\1 ', text)\n",
    "\n",
    "    # Replace back the LaTeX math expressions\n",
    "    for math_expr in math_expressions:\n",
    "        placeholder = math_expr.replace(' ', '_')\n",
    "        text = text.replace(placeholder, math_expr)\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503ddd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.973397Z",
     "start_time": "2023-09-19T16:24:23.928092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply this function to the entire 'content' column\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6429c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.977577Z",
     "start_time": "2023-09-19T16:24:23.974398Z"
    }
   },
   "outputs": [],
   "source": [
    "df['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f228f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.982231Z",
     "start_time": "2023-09-19T16:24:23.978580Z"
    }
   },
   "outputs": [],
   "source": [
    "df['text'].iloc[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba74520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.987249Z",
     "start_time": "2023-09-19T16:24:23.983225Z"
    }
   },
   "outputs": [],
   "source": [
    "df['text'].iloc[336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0a411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:23.991502Z",
     "start_time": "2023-09-19T16:24:23.988246Z"
    }
   },
   "outputs": [],
   "source": [
    "df['text'].iloc[400]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5452ea",
   "metadata": {},
   "source": [
    "# Format size for emebddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c06a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:24.760107Z",
     "start_time": "2023-09-19T16:24:24.752560Z"
    }
   },
   "outputs": [],
   "source": [
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64bb94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:24.997724Z",
     "start_time": "2023-09-19T16:24:24.992724Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7111555e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:25.728520Z",
     "start_time": "2023-09-19T16:24:25.465271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set Seaborn style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['word_count'], bins=50, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Word Counts in Content')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0647559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:26.430906Z",
     "start_time": "2023-09-19T16:24:25.936691Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['word_count'], bins=50, kde=True, color='skyblue')\n",
    "plt.xscale('log')\n",
    "plt.title('Distribution of Word Counts in Content (Logarithmic Scale)')\n",
    "plt.xlabel('Word Count (Log Scale)')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ffc8c",
   "metadata": {},
   "source": [
    "## Remove the empty text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2ad47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:27.062523Z",
     "start_time": "2023-09-19T16:24:27.057930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows where the text is empty\n",
    "df = df[df['text'].notnull() & (df['text'].str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fcb0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:27.536865Z",
     "start_time": "2023-09-19T16:24:27.532336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows where the text is empty or the path is an empty string\n",
    "df = df[(df['path'].notnull()) & (df['path'] != \"\") & (df['text'].str.len() > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5381cbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:28.786369Z",
     "start_time": "2023-09-19T16:24:28.782735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows where path equals \"/Table Of Contents\"\n",
    "df = df[df['path'] != '/Table Of Contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19f08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:29.337920Z",
     "start_time": "2023-09-19T16:24:29.334306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicates based on the 'text' column\n",
    "df = df.drop_duplicates(subset='text', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38873fbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:30.739163Z",
     "start_time": "2023-09-19T16:24:30.732971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find rows with duplicate content\n",
    "duplicates = df[df.duplicated(subset='text', keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0becbf86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:31.583239Z",
     "start_time": "2023-09-19T16:24:31.352237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a new column for word counts\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Plot a histogram of word counts\n",
    "plt.hist(df['word_count'], bins=50, edgecolor='k')\n",
    "plt.title('Distribution of Word Counts')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06b334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:32.306320Z",
     "start_time": "2023-09-19T16:24:32.302104Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='word_count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f98057",
   "metadata": {},
   "source": [
    "# clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e628f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:35.454084Z",
     "start_time": "2023-09-19T16:24:35.449171Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 20  # or any other value based on your visualization or requirements\n",
    "smol = df[df['word_count'] < threshold]\n",
    "final_df = df[df['word_count'] > threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7505750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:35.715145Z",
     "start_time": "2023-09-19T16:24:35.706143Z"
    }
   },
   "outputs": [],
   "source": [
    "smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdaa182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:36.082917Z",
     "start_time": "2023-09-19T16:24:35.905187Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b900e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:36.186237Z",
     "start_time": "2023-09-19T16:24:36.180935Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stopword_percentage(text):\n",
    "    if not text or not isinstance(text, str):\n",
    "        return 0\n",
    "    \n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return 0\n",
    "    \n",
    "    stopword_count = sum(1 for word in words if word.lower() in stop_words)\n",
    "    return (stopword_count / len(words)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d437adb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:36.580617Z",
     "start_time": "2023-09-19T16:24:36.577018Z"
    }
   },
   "outputs": [],
   "source": [
    "smol = smol.copy()  # Making a copy of your DataFrame for this operation\n",
    "smol['score'] = smol['text'].apply(stopword_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f02f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:37.203719Z",
     "start_time": "2023-09-19T16:24:37.193057Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smol = smol.sort_values(by='score', ascending=False)\n",
    "smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0c191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:38.260797Z",
     "start_time": "2023-09-19T16:24:38.061073Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=smol, x='word_count', y='score', alpha=0.6, edgecolor=None)\n",
    "\n",
    "plt.title('Number of Words vs. Stopword Percentage')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Stopword Percentage (%)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a4c1d",
   "metadata": {},
   "source": [
    "# Final preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4fb15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:43.921345Z",
     "start_time": "2023-09-19T16:24:43.912569Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce3553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:46.574278Z",
     "start_time": "2023-09-19T16:24:46.570680Z"
    }
   },
   "outputs": [],
   "source": [
    "has_nan_or_none = df['path'].isnull().any()\n",
    "print(f\"Has NaN or None values in 'path': {has_nan_or_none}\")\n",
    "count_nan_or_none = df['path'].isnull().sum()\n",
    "print(f\"Number of NaN or None values in 'path': {count_nan_or_none}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a079f56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:24:47.376730Z",
     "start_time": "2023-09-19T16:24:47.372186Z"
    }
   },
   "outputs": [],
   "source": [
    "has_empty_string = (df['path'] == \"\").any()\n",
    "print(f\"Has empty strings in 'path': {has_empty_string}\")\n",
    "count_empty_string = (df['path'] == \"\").sum()\n",
    "print(f\"Number of empty strings in 'path': {count_empty_string}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa87cf",
   "metadata": {},
   "source": [
    "# Store in Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc3a468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:25:04.348259Z",
     "start_time": "2023-09-19T16:25:04.176478Z"
    }
   },
   "outputs": [],
   "source": [
    "chroma_client = client = chromadb.PersistentClient(path='C:/Users/Nathan/Kratos_data-Science/Chroma/v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb5a39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:25:04.961637Z",
     "start_time": "2023-09-19T16:25:04.575529Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2',  device='cuda'#cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053ff79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:25:05.012771Z",
     "start_time": "2023-09-19T16:25:04.992640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Chroma\n",
    "vectorstore = chroma_client.get_or_create_collection(name=\"Skyminer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171a93c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:26:30.447513Z",
     "start_time": "2023-09-19T16:26:24.770672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lists to store the extracted information from documents\n",
    "documents_list = []\n",
    "embeddings_list = []\n",
    "metadatas_list = []\n",
    "ids_list = []\n",
    "\n",
    "# Assuming 'content' in your dataframe is what you consider as the document/page_content\n",
    "for _, row in final_df.iterrows():\n",
    "    embedding = model.encode(row['text'])\n",
    "    \n",
    "    # Constructing metadata\n",
    "    metadata = {\n",
    "        \"source\": f\"{row['path']}\",\n",
    "        \"documentation\": row['documentation'],\n",
    "        \"file_path\": row['file_path'],\n",
    "        \"word_count\": row['word_count']\n",
    "    }\n",
    "\n",
    "    documents_list.append(row['text'])\n",
    "    embeddings_list.append(embedding.tolist())\n",
    "    metadatas_list.append(metadata)\n",
    "\n",
    "# Generating IDs for the documents\n",
    "ids_list = [\"v\" + str(i + 1) for i in range(len(documents_list))]\n",
    "\n",
    "# Add the embedded documents to the collection in Chroma\n",
    "vectorstore.add(\n",
    "    documents=documents_list,\n",
    "    embeddings=embeddings_list,\n",
    "    metadatas=metadatas_list,\n",
    "    ids=ids_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c5bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:26:37.633335Z",
     "start_time": "2023-09-19T16:26:37.629540Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3d8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-19T16:26:38.171988Z",
     "start_time": "2023-09-19T16:26:38.168203Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"There are\", vectorstore.count(), \"in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fa146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
